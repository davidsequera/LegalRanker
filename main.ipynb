{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.46.1\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show transformers || pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 1029,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example text\n",
    "text = \"Hello, how are you?\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0824,  0.0667, -0.2880,  ..., -0.3566,  0.1960,  0.5381],\n",
       "         [ 0.0310, -0.1448,  0.0952,  ..., -0.1560,  1.0151,  0.0947],\n",
       "         [-0.8935,  0.3240,  0.4184,  ..., -0.5498,  0.2853,  0.1149],\n",
       "         ...,\n",
       "         [-0.2812, -0.8531,  0.6912,  ..., -0.5051,  0.4716, -0.6854],\n",
       "         [-0.4429, -0.7820, -0.8055,  ...,  0.1949,  0.1081,  0.0130],\n",
       "         [ 0.5570, -0.1080, -0.2412,  ...,  0.2817, -0.3996, -0.1882]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9397, -0.4081, -0.9024,  0.8667,  0.6076, -0.1782,  0.9319,  0.2685,\n",
       "         -0.7918, -1.0000, -0.4899,  0.9625,  0.9823,  0.6102,  0.9614, -0.8728,\n",
       "         -0.6449, -0.6543,  0.3102, -0.6648,  0.7556,  1.0000,  0.0778,  0.3350,\n",
       "          0.5094,  0.9948, -0.8847,  0.9590,  0.9761,  0.7384, -0.7787,  0.1232,\n",
       "         -0.9912, -0.2119, -0.9225, -0.9931,  0.3767, -0.8050, -0.0945,  0.0497,\n",
       "         -0.9269,  0.2934,  1.0000,  0.0954,  0.4904, -0.3206, -1.0000,  0.2759,\n",
       "         -0.9303,  0.9396,  0.9162,  0.8490,  0.1967,  0.4833,  0.5391,  0.0523,\n",
       "         -0.0621,  0.1046, -0.3403, -0.6018, -0.6203,  0.5439, -0.8909, -0.9180,\n",
       "          0.9392,  0.8156, -0.1900, -0.2589, -0.1371, -0.1553,  0.9367,  0.3183,\n",
       "          0.2468, -0.9167,  0.5823,  0.2861, -0.7534,  1.0000, -0.7911, -0.9841,\n",
       "          0.8615,  0.7741,  0.6616, -0.2575,  0.4217, -1.0000,  0.6669, -0.1115,\n",
       "         -0.9931,  0.1993,  0.6389, -0.3458,  0.3185,  0.6436, -0.6661, -0.4977,\n",
       "         -0.3677, -0.8909, -0.3536, -0.3582,  0.1323, -0.2020, -0.5409, -0.4236,\n",
       "          0.3375, -0.5047, -0.6625,  0.3016, -0.1905,  0.7032,  0.4906, -0.3784,\n",
       "          0.5841, -0.9767,  0.6868, -0.4095, -0.9919, -0.6602, -0.9917,  0.7231,\n",
       "         -0.4432, -0.3315,  0.9772, -0.0030,  0.5428, -0.1079, -0.9419, -1.0000,\n",
       "         -0.8208, -0.7195, -0.1495, -0.3632, -0.9843, -0.9785,  0.6604,  0.9671,\n",
       "          0.1991,  0.9999, -0.3270,  0.9683, -0.2824, -0.6671,  0.6429, -0.5084,\n",
       "          0.8155,  0.6683, -0.7370,  0.1841, -0.3255,  0.5425, -0.8196, -0.1444,\n",
       "         -0.7372, -0.9632, -0.4311,  0.9677, -0.5258, -0.9448,  0.0683, -0.2570,\n",
       "         -0.6629,  0.8783,  0.8162,  0.4679, -0.4237,  0.4789,  0.3930,  0.6878,\n",
       "         -0.9157, -0.1113,  0.5141, -0.3371, -0.8507, -0.9828, -0.4308,  0.6103,\n",
       "          0.9940,  0.8002,  0.3561,  0.8153, -0.2915,  0.8075, -0.9715,  0.9865,\n",
       "         -0.2685,  0.2925,  0.0508,  0.4006, -0.9311,  0.0247,  0.8974, -0.6805,\n",
       "         -0.8900, -0.2348, -0.5269, -0.4351, -0.8138,  0.6458, -0.2967, -0.2653,\n",
       "         -0.1253,  0.9394,  0.9895,  0.8081,  0.2221,  0.8180, -0.9162, -0.5713,\n",
       "          0.0396,  0.3294,  0.1492,  0.9960, -0.7699, -0.1358, -0.9500, -0.9895,\n",
       "         -0.0589, -0.9379, -0.2007, -0.7227,  0.7361,  0.1222,  0.5693,  0.5728,\n",
       "         -0.9927, -0.7939,  0.3953, -0.5294,  0.4758, -0.2439,  0.6086,  0.9451,\n",
       "         -0.6614,  0.8475,  0.9563, -0.8955, -0.8207,  0.8418, -0.3480,  0.9098,\n",
       "         -0.7207,  0.9900,  0.9613,  0.9021, -0.9444, -0.7457, -0.9020, -0.7801,\n",
       "         -0.0605,  0.1208,  0.9016,  0.6999,  0.4337,  0.3760, -0.7694,  0.9992,\n",
       "         -0.6057, -0.9718, -0.4017, -0.1144, -0.9907,  0.9075,  0.3436,  0.3461,\n",
       "         -0.4579, -0.7868, -0.9760,  0.9109,  0.1416,  0.9900, -0.1437, -0.9715,\n",
       "         -0.5963, -0.9475, -0.2035, -0.2663, -0.2594, -0.1224, -0.9710,  0.5504,\n",
       "          0.5669,  0.6306, -0.7672,  0.9996,  1.0000,  0.9747,  0.9272,  0.9433,\n",
       "         -0.9999, -0.6034,  1.0000, -0.9959, -1.0000, -0.9484, -0.7638,  0.4284,\n",
       "         -1.0000, -0.2423, -0.0149, -0.9346,  0.7198,  0.9799,  0.9970, -1.0000,\n",
       "          0.8571,  0.9582, -0.7485,  0.9826, -0.5256,  0.9773,  0.5886,  0.3242,\n",
       "         -0.3219,  0.3844, -0.9395, -0.9149, -0.5524, -0.7445,  0.9986,  0.2265,\n",
       "         -0.8418, -0.9291,  0.3760, -0.2026, -0.3773, -0.9807, -0.2517,  0.6540,\n",
       "          0.8830,  0.1926,  0.3737, -0.7180,  0.3621, -0.0460,  0.2923,  0.7520,\n",
       "         -0.9328, -0.4846, -0.3400, -0.3362, -0.6643, -0.9751,  0.9772, -0.4883,\n",
       "          0.9261,  1.0000,  0.1624, -0.9297,  0.7345,  0.2806, -0.3267,  1.0000,\n",
       "          0.8273, -0.9825, -0.6232,  0.5221, -0.6021, -0.6570,  0.9997, -0.1715,\n",
       "         -0.6950, -0.5274,  0.9871, -0.9913,  0.9965, -0.9464, -0.9779,  0.9795,\n",
       "          0.9524, -0.8368, -0.7578,  0.2502, -0.7006,  0.2992, -0.9726,  0.8163,\n",
       "          0.6003, -0.1536,  0.9077, -0.9091, -0.6684,  0.2876, -0.7330, -0.1607,\n",
       "          0.9486,  0.6312, -0.3891,  0.0357, -0.3750, -0.3756, -0.9843,  0.4886,\n",
       "          1.0000, -0.2315,  0.7898, -0.4258, -0.0598, -0.1328,  0.5125,  0.6314,\n",
       "         -0.3294, -0.8755,  0.7849, -0.9849, -0.9887,  0.8402,  0.1892, -0.4375,\n",
       "          1.0000,  0.5749,  0.1210,  0.4122,  0.9909,  0.0735,  0.7185,  0.8889,\n",
       "          0.9896, -0.2700,  0.6525,  0.9098, -0.9027, -0.4159, -0.7008, -0.0415,\n",
       "         -0.9281, -0.0108, -0.9747,  0.9768,  0.9692,  0.4282,  0.2692,  0.6122,\n",
       "          1.0000, -0.5248,  0.7249, -0.5060,  0.9194, -0.9998, -0.9260, -0.4517,\n",
       "         -0.1464, -0.8025, -0.4218,  0.4552, -0.9794,  0.8356,  0.6287, -0.9972,\n",
       "         -0.9938, -0.2074,  0.9298,  0.1215, -0.9909, -0.8170, -0.6627,  0.6416,\n",
       "         -0.2284, -0.9569, -0.1181, -0.3816,  0.5255, -0.1805,  0.6387,  0.8702,\n",
       "          0.6870, -0.5757, -0.4236, -0.1641, -0.8831,  0.9374, -0.8926, -0.9400,\n",
       "         -0.3102,  1.0000, -0.6176,  0.9136,  0.7730,  0.7931, -0.0889,  0.2407,\n",
       "          0.9472,  0.3261, -0.7425, -0.8732, -0.7849, -0.4377,  0.8024,  0.3961,\n",
       "          0.7152,  0.8478,  0.8273,  0.1153, -0.0280, -0.0304,  0.9999, -0.2497,\n",
       "         -0.1616, -0.5044, -0.0497, -0.4457, -0.5473,  1.0000,  0.3189,  0.5105,\n",
       "         -0.9929, -0.9074, -0.9470,  1.0000,  0.8645, -0.8185,  0.7758,  0.6998,\n",
       "         -0.1522,  0.8929, -0.2187, -0.4045,  0.3307,  0.1409,  0.9588, -0.6211,\n",
       "         -0.9823, -0.7474,  0.4825, -0.9754,  1.0000, -0.6499, -0.2883, -0.5406,\n",
       "         -0.1761,  0.3477, -0.1121, -0.9871, -0.2494,  0.3136,  0.9691,  0.3786,\n",
       "         -0.6823, -0.9428,  0.7981,  0.8634, -0.9307, -0.9558,  0.9710, -0.9912,\n",
       "          0.6371,  1.0000,  0.3606,  0.0868,  0.2708, -0.5297,  0.4133, -0.4391,\n",
       "          0.8383, -0.9726, -0.3193, -0.2312,  0.3197, -0.1520, -0.2309,  0.8155,\n",
       "          0.2249, -0.6628, -0.7201, -0.0532,  0.4476,  0.9189, -0.2601, -0.2309,\n",
       "          0.1324, -0.1847, -0.9499, -0.2363, -0.5325, -1.0000,  0.7762, -1.0000,\n",
       "          0.5303,  0.2326, -0.2700,  0.9060,  0.2731,  0.5734, -0.8361, -0.8113,\n",
       "          0.5569,  0.8021, -0.3536, -0.6216, -0.7758,  0.4175, -0.0477,  0.1000,\n",
       "         -0.5561,  0.7914, -0.2158,  1.0000,  0.2179, -0.8865, -0.9858,  0.1659,\n",
       "         -0.3391,  1.0000, -0.9481, -0.9695,  0.5338, -0.8202, -0.8819,  0.4277,\n",
       "          0.0594, -0.8486, -0.9633,  0.9736,  0.9464, -0.6571,  0.4920, -0.3911,\n",
       "         -0.6615,  0.0692,  0.8727,  0.9897,  0.4700,  0.9277,  0.6218, -0.2349,\n",
       "          0.9815,  0.2672,  0.5438,  0.0797,  1.0000,  0.3870, -0.9405,  0.1054,\n",
       "         -0.9833, -0.2969, -0.9634,  0.3935,  0.2849,  0.9189, -0.2147,  0.9719,\n",
       "         -0.8230,  0.0331, -0.7876, -0.4855,  0.4738, -0.9335, -0.9865, -0.9889,\n",
       "          0.6081, -0.4843, -0.0682,  0.1664,  0.1078,  0.4640,  0.4898, -1.0000,\n",
       "          0.9641,  0.5431,  0.9383,  0.9721,  0.7680,  0.5263,  0.3403, -0.9916,\n",
       "         -0.9905, -0.3485, -0.2593,  0.7984,  0.6853,  0.9404,  0.5173, -0.5142,\n",
       "         -0.1765, -0.4202, -0.4569, -0.9952,  0.5883, -0.5553, -0.9812,  0.9735,\n",
       "         -0.3406, -0.1781, -0.0011, -0.8343,  0.9537,  0.8525,  0.4713, -0.0046,\n",
       "          0.5341,  0.9080,  0.9707,  0.9846, -0.8114,  0.9081, -0.6079,  0.5477,\n",
       "          0.8132, -0.9515,  0.0974,  0.5627, -0.5420,  0.3376, -0.2709, -0.9814,\n",
       "          0.7589, -0.3889,  0.6699, -0.4872,  0.0730, -0.4788, -0.0787, -0.7815,\n",
       "         -0.8119,  0.6705,  0.6675,  0.9399,  0.7869, -0.0141, -0.7990, -0.1767,\n",
       "         -0.8166, -0.9326,  0.9578, -0.0282, -0.3473,  0.6796, -0.0607,  0.8229,\n",
       "          0.1077, -0.3942, -0.3221, -0.7277,  0.8907, -0.5713, -0.5725, -0.6333,\n",
       "          0.7569,  0.3500,  1.0000, -0.7834, -0.9078, -0.4479, -0.3861,  0.5302,\n",
       "         -0.7148, -1.0000,  0.4726, -0.4242,  0.7148, -0.7536,  0.8473, -0.7694,\n",
       "         -0.9885, -0.3057,  0.5318,  0.7787, -0.4794, -0.6866,  0.6466, -0.1783,\n",
       "          0.9834,  0.9262, -0.6138,  0.2273,  0.6907, -0.7303, -0.7535,  0.9454]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model outputs\n",
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states = outputs.last_hidden_state\n",
    "pooled_output = outputs.pooler_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
